# -*- coding: utf-8 -*-
"""markovian and non markovian and quantum jump monte carlo .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rx4WSj_4KHmiMu1MACmdNMCjFCIBIlOd
"""

import numpy as np
import matplotlib.pyplot as plt
import networkx as nx

# --- 1. Define the Markov Chain ---
# Transition matrix P, where P[i][j] is the probability of moving from state i to state j.
# The rows must sum to 1.
P = np.array([[0.2, 0.6, 0.2],
              [0.3, 0.4, 0.3],
              [0.1, 0.3, 0.6]])

# --- 2. Simulate the Convergence ---
# Number of time steps for the simulation
n_steps = 50

# Initial state distribution (must sum to 1)
# We start in state 0 with probability 1.
initial_state = np.array([1.0, 0.0, 0.0])

# History of state distributions
state_history = np.zeros((n_steps, 3))
state_history[0] = initial_state

# Simulate the chain
current_state = initial_state
for i in range(1, n_steps):
    current_state = np.dot(current_state, P)
    state_history[i] = current_state

# --- 3. Calculate the Steady-State Distribution ---
# The steady-state is the left eigenvector of P corresponding to the eigenvalue 1.
eigenvalues, eigenvectors = np.linalg.eig(P.T)
steady_state_vector = np.real(eigenvectors[:, np.isclose(eigenvalues, 1)])
steady_state_vector = steady_state_vector[:, 0]
steady_state = steady_state_vector / np.sum(steady_state_vector)

print("Transition Matrix (P):\n", P)
print("\nCalculated Steady-State Distribution:", steady_state)


# --- 4. Plot the Convergence to Steady State ---
plt.figure(figsize=(12, 6))
plt.plot(state_history[:, 0], label='State 0')
plt.plot(state_history[:, 1], label='State 1')
plt.plot(state_history[:, 2], label='State 2')

# Plot the steady-state probabilities as horizontal lines
plt.axhline(y=steady_state[0], color='r', linestyle='--', label=f'Steady State 0 ({steady_state[0]:.2f})')
plt.axhline(y=steady_state[1], color='g', linestyle='--', label=f'Steady State 1 ({steady_state[1]:.2f})')
plt.axhline(y=steady_state[2], color='b', linestyle='--', label=f'Steady State 2 ({steady_state[2]:.2f})')

plt.title('Convergence of a 3-State Markov Chain to Steady State')
plt.xlabel('Time Steps')
plt.ylabel('Probability')
plt.legend()
plt.grid(True)
plt.show()


# --- 5. Visualize the Markov Chain as a Network ---
G = nx.MultiDiGraph()

# Add nodes
for i in range(P.shape[0]):
    G.add_node(i, label=f'State {i}')

# Add edges with probabilities as labels
for i in range(P.shape[0]):
    for j in range(P.shape[1]):
        if P[i, j] > 0:
            G.add_edge(i, j, weight=P[i, j], label=f'{P[i, j]:.2f}')

pos = nx.spring_layout(G, seed=42)  # For reproducible layout
edge_labels = nx.get_edge_attributes(G, 'label')

plt.figure(figsize=(10, 8))
nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=2500,
        connectionstyle='arc3,rad=0.1', arrowsize=20)
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='red')

plt.title('Network Representation of the 3-State Markov Chain')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import random

# --- 1. Define the Non-Markovian Transition Rules ---
# P(next=0 | (state_t-1, state_t))
prob_next_is_0 = {
    (0, 0): 0.9,
    (0, 1): 0.3,
    (1, 0): 0.6,
    (1, 1): 0.1
}

# --- 2. Direct Simulation of the Chain with Memory ---
n_steps = 200
# Start with a history of (0, 0)
history = [0, 0]

for _ in range(n_steps):
    last_two = tuple(history[-2:])
    prob_0 = prob_next_is_0[last_two]

    if random.random() < prob_0:
        history.append(0)
    else:
        history.append(1)

# Calculate the proportion of time spent in each state
state_0_proportion = np.cumsum([1 if s == 0 else 0 for s in history]) / np.arange(1, len(history) + 1)
state_1_proportion = 1 - state_0_proportion

# --- 3. Plot the Direct Simulation Results ---
plt.figure(figsize=(12, 6))
plt.plot(state_0_proportion, label='Proportion in State 0')
plt.plot(state_1_proportion, label='Proportion in State 1')
plt.title('Direct Simulation of a Chain with Memory')
plt.xlabel('Time Steps')
plt.ylabel('Proportion of Time in State')
plt.ylim(0, 1)
plt.grid(True)
plt.legend()
plt.show()

print(f"Final proportion in State 0 (Direct Sim): {state_0_proportion[-1]:.4f}")
print(f"Final proportion in State 1 (Direct Sim): {state_1_proportion[-1]:.4f}")

import numpy as np
import matplotlib.pyplot as plt
import random
import networkx as nx
from collections import Counter

# ==============================================================================
# PART 1: DIRECT SIMULATION (FROM PREVIOUS EXAMPLE)
# We run this first to get a 'history' to build the observed network.
# ==============================================================================

# --- 1.1 Define the Non-Markovian Transition Rules ---
# P(next=0 | (state_t-1, state_t))
prob_next_is_0 = {
    (0, 0): 0.9,
    (0, 1): 0.3,
    (1, 0): 0.6,
    (1, 1): 0.1
}

# --- 1.2 Direct Simulation of the Chain with Memory ---
n_steps = 500  # Using more steps for a better frequency count
# Start with a history of (0, 0)
history = [0, 0]

for _ in range(n_steps):
    last_two = tuple(history[-2:])
    prob_0 = prob_next_is_0[last_two]

    if random.random() < prob_0:
        history.append(0)
    else:
        history.append(1)

# ==============================================================================
# PART 2: VISUALIZE THE NON-MARKOVIAN CHAIN'S OBSERVED BEHAVIOR
# ==============================================================================

# --- 2.1 Create a network based on observed transition frequencies ---
G_observed = nx.DiGraph()
transitions = list(zip(history, history[1:]))
counts = Counter(transitions)
total_transitions = len(transitions)

for (u, v), count in counts.items():
    G_observed.add_edge(u, v, weight=count, label=f'{count/total_transitions:.2f}')

plt.figure(figsize=(10, 8))
pos_observed = nx.spring_layout(G_observed, seed=42)
edge_labels_observed = nx.get_edge_attributes(G_observed, 'label')

nx.draw(G_observed, pos_observed, with_labels=True, node_color='salmon', node_size=3000,
        connectionstyle='arc3,rad=0.1', arrowsize=20)
nx.draw_networkx_edge_labels(G_observed, pos_observed, edge_labels=edge_labels_observed, font_color='black')
plt.title('Network of Observed Transitions (Non-Markovian Behavior)')
plt.show()

# ==============================================================================
# PART 3: STATE-SPACE EXPANSION SIMULATION AND VISUALIZATION
# ==============================================================================

# --- 3.1 Define the Expanded State Space and Transition Matrix ---
# States: 0=(0,0), 1=(0,1), 2=(1,0), 3=(1,1)
P_expanded = np.array([
    # From (0,0): next can be (0,0) or (0,1)
    [0.9, 0.1, 0.0, 0.0],
    # From (0,1): next can be (1,0) or (1,1)
    [0.0, 0.0, 0.3, 0.7],
    # From (1,0): next can be (0,0) or (0,1)
    [0.6, 0.4, 0.0, 0.0],
    # From (1,1): next can be (1,0) or (1,1)
    [0.0, 0.0, 0.1, 0.9]
])

# --- 3.2 Simulate the Expanded (Memoryless) Markov Chain ---
n_steps_expanded = 50
# Start in state 0, which corresponds to (0,0)
initial_state_expanded = np.array([1.0, 0.0, 0.0, 0.0])

state_history_expanded = np.zeros((n_steps_expanded, 4))
state_history_expanded[0] = initial_state_expanded

current_state_dist = initial_state_expanded
for i in range(1, n_steps_expanded):
    current_state_dist = np.dot(current_state_dist, P_expanded)
    state_history_expanded[i] = current_state_dist

# --- 3.3 Plot the Full State Space Convergence Over Time ---
plt.figure(figsize=(12, 7))
super_state_labels = ['State (0,0)', 'State (0,1)', 'State (1,0)', 'State (1,1)']
for i in range(4):
    plt.plot(state_history_expanded[:, i], label=super_state_labels[i])

plt.title('Convergence of the Full Expanded State Space')
plt.xlabel('Time Steps')
plt.ylabel('Probability')
plt.grid(True)
plt.legend()
plt.show()


# --- 3.4 Visualize the Expanded Markovian Network ---
G_expanded = nx.DiGraph()
labels = {0: '(0,0)', 1: '(0,1)', 2: '(1,0)', 3: '(1,1)'}

for i in range(P_expanded.shape[0]):
    for j in range(P_expanded.shape[1]):
        if P_expanded[i, j] > 0:
            G_expanded.add_edge(labels[i], labels[j], weight=P_expanded[i, j], label=f'{P_expanded[i, j]:.2f}')

pos_expanded = nx.circular_layout(G_expanded)
edge_labels_expanded = nx.get_edge_attributes(G_expanded, 'label')

plt.figure(figsize=(10, 8))
nx.draw(G_expanded, pos_expanded, with_labels=True, node_color='lightblue', node_size=3500,
        connectionstyle='arc3,rad=0.2', arrowsize=20)
nx.draw_networkx_edge_labels(G_expanded, pos_expanded, edge_labels=edge_labels_expanded, font_color='black')
plt.title('Network of the Expanded (Memoryless) Markov Chain')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import random
import networkx as nx
from collections import Counter

# ==============================================================================
# PART 1: DIRECT SIMULATION & SETUP
# ==============================================================================

# --- 1.1 Define the Non-Markovian Transition Rules ---
# P(next=0 | (state_t-1, state_t))
prob_next_is_0 = {
    (0, 0): 0.9,
    (0, 1): 0.3,
    (1, 0): 0.6,
    (1, 1): 0.1
}

# --- 1.2 Function to run a single simulation ---
def run_simulation(steps):
    """Runs one instance of the direct simulation and returns its history."""
    # Start with a history of (0, 0)
    history = [0, 0]
    for _ in range(steps):
        last_two = tuple(history[-2:])
        prob_0 = prob_next_is_0[last_two]

        if random.random() < prob_0:
            history.append(0)
        else:
            history.append(1)
    return history

# --- 1.3 Run a single simulation for the first set of plots ---
n_steps = 200
first_run_history = run_simulation(n_steps)

# ==============================================================================
# NEW VISUALIZATION 1: PLOT OF A SINGLE, EXACT PATH
# ==============================================================================

plt.figure(figsize=(15, 4))
# Use a step plot for clear visualization of discrete state changes
plt.step(range(len(first_run_history)), first_run_history, where='post')
plt.title('Exact Path of a Single Simulation Run')
plt.xlabel('Time Step')
plt.ylabel('State')
plt.yticks([0, 1]) # Ensure y-axis only shows 0 and 1
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.ylim(-0.1, 1.1)
plt.show()

# ==============================================================================
# NEW VISUALIZATION 2: ENSEMBLE PLOT OF MULTIPLE PATHS
# ==============================================================================

# --- 2.1 Generate the ensemble ---
num_runs = 50  # Number of simulations in the ensemble
ensemble_histories = []
for i in range(num_runs):
    # Add a progress indicator
    print(f"Running simulation {i+1}/{num_runs}...", end='\r')
    ensemble_histories.append(run_simulation(n_steps))
print("\nEnsemble generation complete.")

# --- 2.2 Plot the ensemble ---
plt.figure(figsize=(15, 6))
for i, history in enumerate(ensemble_histories):
    # Plot each run with high transparency (low alpha)
    # The last run is plotted with full opacity and a label for clarity in the legend
    if i == num_runs - 1:
        plt.step(range(len(history)), history, where='post', alpha=0.7, color='red', linewidth=1.5, label='One Path')
    else:
        plt.step(range(len(history)), history, where='post', alpha=0.15, color='gray', linewidth=1.0)

plt.title(f'Ensemble of {num_runs} Simulation Paths')
plt.xlabel('Time Step')
plt.ylabel('State')
plt.yticks([0, 1])
plt.ylim(-0.1, 1.1)
plt.legend()
plt.show()


# ==============================================================================
# (Optional) The other plots from before can still be run using the 'first_run_history'
# For brevity, they are omitted here but the code from the previous step is still valid.
# ==============================================================================

import numpy as np
import matplotlib.pyplot as plt
import random

# ==============================================================================
# SETUP AND SIMULATION
# ==============================================================================

# --- 1. Define the Non-Markovian Transition Rules ---
prob_next_is_0 = {
    (0, 0): 0.9,
    (0, 1): 0.3,
    (1, 0): 0.6,
    (1, 1): 0.1
}

# --- 2. Function to run a single direct simulation ---
def run_simulation(steps):
    """Runs one instance of the direct simulation and returns its history."""
    history = [0, 0]
    for _ in range(steps):
        last_two = tuple(history[-2:])
        prob_0 = prob_next_is_0[last_two]
        if random.random() < prob_0:
            history.append(0)
        else:
            history.append(1)
    return history

# --- 3. Generate a large ensemble of direct simulations ---
n_steps = 100  # Number of steps in each simulation
num_runs = 500 # Use a larger ensemble for a smoother average

print(f"Generating ensemble of {num_runs} runs...")
ensemble_histories = []
for i in range(num_runs):
    ensemble_histories.append(run_simulation(n_steps))
print("Ensemble generation complete.")

# --- 4. Calculate the theoretical probability from the expanded state model ---
P_expanded = np.array([
    [0.9, 0.1, 0.0, 0.0], [0.0, 0.0, 0.3, 0.7],
    [0.6, 0.4, 0.0, 0.0], [0.0, 0.0, 0.1, 0.9]
])
initial_state_expanded = np.array([1.0, 0.0, 0.0, 0.0])
state_history_expanded = np.zeros((n_steps + 2, 4))
state_history_expanded[0] = initial_state_expanded
current_state_dist = initial_state_expanded
for i in range(1, n_steps + 2):
    current_state_dist = np.dot(current_state_dist, P_expanded)
    state_history_expanded[i] = current_state_dist
# Theoretical probability of being in original State 1
prob_in_state_1_theoretical = state_history_expanded[:, 1] + state_history_expanded[:, 3]


# ==============================================================================
# NEW VISUALIZATION: ENSEMBLE AVERAGE VS. THEORETICAL PROBABILITY
# ==============================================================================

# --- 5. Calculate the average state of the ensemble at each time step ---
# Convert list of lists to a 2D NumPy array for efficient calculation
ensemble_array = np.array(ensemble_histories)
# Calculate the mean down the columns (axis=0). This gives the proportion
# of simulations in State 1 at each time step.
ensemble_average_state1 = np.mean(ensemble_array, axis=0)

# --- 6. Plot the comparison ---
plt.figure(figsize=(14, 7))
# Plot the average of the 500 direct simulations
plt.plot(ensemble_average_state1,
         label=f'Average of {num_runs} Direct Simulations',
         color='dodgerblue',
         linewidth=4)

# Plot the theoretical result from the expanded state-space model
plt.plot(prob_in_state_1_theoretical,
         label='Theoretical Probability from Expanded Model',
         color='red',
         linestyle='--',
         linewidth=2)

plt.title('Ensemble Average vs. Theoretical Probability of Being in State 1', fontsize=16)
plt.xlabel('Time Step', fontsize=12)
plt.ylabel('Proportion / Probability in State 1', fontsize=12)
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.legend(fontsize=12)
plt.show()

!pip install qutip

import matplotlib.pyplot as plt
import numpy as np
from qutip import *
from IPython.display import Image

# Assuming the previous setup code is unchanged
N = 4               # number of basis states to consider
kappa = 1.0/0.129   # coupling to heat bath
nth = 0.063         # temperature with <n>=0.063
tlist = np.linspace(0, 0.6, 100)
a = destroy(N)      # cavity destruction operator
H = a.dag() * a     # harmonic oscillator Hamiltonian
psi0 = basis(N, 1)  # initial Fock state with one photon: |1>
c_op_list = []

# Decay operator
c_op_list.append(np.sqrt(kappa * (1 + nth)) * a)

# Excitation operator
c_op_list.append(np.sqrt(kappa * nth) * a.dag())

# List of number of trajectories to avg. over
ntraj_list = [1, 5, 15, 904]

# Run mcsolve for each ntraj value and store results
mc_results = []
for n in ntraj_list:
    mc = mcsolve(H, psi0, tlist, c_op_list, e_ops=[a.dag()*a], ntraj=n)
    mc_results.append(mc)

# Run mesolve for master equation
me = mesolve(H, psi0, tlist, c_op_list, e_ops=[a.dag()*a])

# Calculate final state using steadystate solver
final_state = steadystate(H, c_op_list)
fexpt = expect(a.dag()*a, final_state)

# Plotting
import matplotlib.font_manager
leg_prop = matplotlib.font_manager.FontProperties(size=10)

fig, axes = plt.subplots(4, 1, sharex=True, figsize=(8, 12))
fig.subplots_adjust(hspace=0.1)  # reduce space between plots

for idx, (n, mc) in enumerate(zip(ntraj_list, mc_results)):
    axes[idx].step(tlist, mc.expect[0], 'b', lw=2)
    axes[idx].plot(tlist, me.expect[0], 'r--', lw=1.5)
    axes[idx].axhline(y=fexpt, color='k', lw=1.5)

    axes[idx].set_yticks(np.linspace(0, 2, 5))
    axes[idx].set_ylim([0, 1.5])
    axes[idx].set_ylabel(r'$\left<N\right>$', fontsize=14)

    if idx == 0:
        axes[idx].set_title("Ensemble Averaging of Monte Carlo Trajectories")
        axes[idx].legend(('Single trajectory', 'master equation', 'steady state'), prop=leg_prop)
    else:
        axes[idx].legend(('%d trajectories' % n, 'master equation', 'steady state'), prop=leg_prop)

axes[3].xaxis.set_major_locator(plt.MaxNLocator(4))
axes[3].set_xlabel('Time (sec)', fontsize=14)
plt.show()